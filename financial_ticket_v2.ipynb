{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reference: https://www.kaggle.com/code/venkatasubramanian/automatic-ticket-classification-notebook#Topic-Modelling-using-NMF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk import pos_tag\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "from textblob import TextBlob\n",
    "import re\n",
    "\n",
    "# Download NLTK resources\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.json_normalize(json.load(open(\"complaints-2021-05-14_08_16_.json\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Data Understanding\n",
    "\n",
    "- getting basic information such as number of variables, observations, sample data, and value frequencies\n",
    "- identifying data quality issues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Assign new column names\n",
    "df.columns = ['index', 'type', 'id', 'score', 'tags', 'zip_code','complaint_id', 'issue', 'date_received',\n",
    "       'state', 'consumer_disputed', 'product','company_response', 'company', 'submitted_via',\n",
    "       'date_sent_to_company', 'company_public_response','sub_product', 'timely',\n",
    "       'complaint_what_happened', 'sub_issue','consumer_consent_provided']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.value_counts('type')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.value_counts('tags')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.value_counts('issue')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.value_counts('consumer_disputed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.value_counts('product')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.value_counts('sub_product')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.value_counts('timely')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.value_counts('complaint_what_happened')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.value_counts('sub_issue')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.value_counts('consumer_consent_provided')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# null or empty values\n",
    "null_count_df = pd.DataFrame({'columns':df.columns,\n",
    "                              'empty_string_count':list(map(lambda column: (df[column] == '').sum(), df.columns)),\n",
    "                              'null_value_count':list(map(lambda column: (df[column] == np.nan).sum(), df.columns))})\n",
    "null_count_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# masked values\n",
    "masked_text_pattern = r\"\\b[x|X]{2,20}\"\n",
    "masked_df = pd.DataFrame({\n",
    "    'number_of_masked':df['complaint_what_happened'].apply(lambda text:len(re.findall(masked_text_pattern, text))), \n",
    "    'masked':df['complaint_what_happened'].apply(lambda text:re.findall(masked_text_pattern, text))})\n",
    "df_with_masked = masked_df[masked_df['number_of_masked']!=0]\n",
    "df_with_masked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_with_masked.value_counts('number_of_masked')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.hist(df_with_masked['number_of_masked'],bins=200)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initial Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "  # Case-folding (Lowercase)\n",
    "  text = text.lower()\n",
    "\n",
    "  # Remove url\n",
    "  url_pattern = re.compile(r'(https?://\\S+)|(www\\.\\S+)|(\\S+\\.\\S+/\\S+)')\n",
    "  text = url_pattern.sub(r'', text)\n",
    "\n",
    "  # Remove emoji\n",
    "  emoji_pattern = re.compile(\"[\"\n",
    "                                u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "                                u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "                                u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "                                u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                                u\"\\U00002702-\\U000027B0\"  # other miscellaneous symbols\n",
    "                                u\"\\U000024C2-\\U0001F251\"  # enclosed characters\n",
    "                              \"]+\", flags=re.UNICODE)\n",
    "  text = emoji_pattern.sub(r'', text)\n",
    "\n",
    "  # Remove Punctuation, and words containing numbers\n",
    "  punt_pattern = '[^\\w\\s]'\n",
    "  word_with_num_pattern = '\\w*\\d\\w*'\n",
    "  text = re.sub(punt_pattern, '', text)\n",
    "  text = re.sub(word_with_num_pattern, '', text)\n",
    "\n",
    "  # Tokenisation\n",
    "  tokens = word_tokenize(text)\n",
    "\n",
    "  # Remove stopwords\n",
    "  stop_words = set(stopwords.words('english'))\n",
    "  tokens = [word for word in tokens if word not in stop_words]\n",
    "\n",
    "  return tokens\n",
    "\n",
    "def lemmatise_with_pos_tagged(tokens):\n",
    "  lemmatizer = WordNetLemmatizer()\n",
    "  lemmas = []\n",
    "  for word, tag in pos_tag(tokens):\n",
    "    wntag = tag[0].lower()\n",
    "    wntag = wntag if wntag in ['a', 'r', 'n', 'v'] else None\n",
    "    lemmas.append(lemmatizer.lemmatize(word, wntag) if wntag else word)\n",
    "  return lemmas\n",
    "\n",
    "def further_clean(tokens):\n",
    "  # remove repeating characters from tokens\n",
    "  RepeatTokensRm =  \" \".join( [ re.sub(r'(\\w)\\1{2,}', r'\\1', word) for word in tokens] )\n",
    "  # Remove tokens containing digits\n",
    "  digitTokensRm =  \" \".join( [ word for word in RepeatTokensRm.split() if not re.search(r'\\d', word) ] ) \n",
    "  # Remove tokens containing underscore\n",
    "  underscoreTokensRm =  \" \".join( [ word for word in digitTokensRm.split() if not re.search(r'_|\\w*_\\w*', word) ] )\n",
    "  # Remove tokens containing Special Characters\n",
    "  specialTokensRm =  \" \".join( [ word for word in underscoreTokensRm.split() if not re.search(r'[^a-zA-Z0-9\\s]', word) ] )\n",
    "  # Remove tokens less than 2 characters\n",
    "  return \" \".join( [ word for word in specialTokensRm.split() if len(word) > 2 ] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    tokens = clean_text(text)\n",
    "    lemmas = lemmatise_with_pos_tagged(tokens)\n",
    "    preprocessed_text = further_clean(lemmas)\n",
    "    return preprocessed_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop unnecessary columns\n",
    "df.drop(['index', 'type', 'id', 'score', 'tags', 'zip_code','complaint_id', 'issue', 'date_received',\n",
    "       'state', 'consumer_disputed', 'product','company_response', 'company', 'submitted_via',\n",
    "       'date_sent_to_company', 'company_public_response','sub_product', 'timely',\n",
    "       'sub_issue','consumer_consent_provided'],axis=1,inplace=True)\n",
    "\n",
    "# remove values containing empty strings or only whitespaces of complaint_what_happened column\n",
    "df['complaint_what_happened'].replace(r'^\\s*$', np.nan, regex=True, inplace=True)\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "# Apply text preprocessing to the 'complaint_what_happened' column\n",
    "df['preprocessed_text'] = df['complaint_what_happened'].apply(preprocess_text)\n",
    "\n",
    "# Display the preprocessed text\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_complain_text['complaint_clean'] = df_complain_text['complaint_what_happened'].apply(clean_text)\n",
    "# print(\"Done clean\")\n",
    "# df_complain_text['complaint_pos_tagged'] = df_complain_text['complaint_clean'].apply(pos_tagger)\n",
    "# print(\"Done lemmatisation\")\n",
    "# df_complain_text['complaint_lemmatise'] = df_complain_text['complaint_pos_tagged'].apply(lemmatise)\n",
    "# print(\"POS Tagged\")\n",
    "# df_complain_processed = df_complain_text[['complaint_clean','complaint_what_happened','complaint_pos_tagged','complaint_lemmatise']]\n",
    "# df_complain_processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove individual \"i\", \"I\", \"s\", \"xxxx\", \"xxxxxxxx\"\n",
    "# def clean_specific_unigram(sentence):\n",
    "#     unigram_to_remove = [\"i\", \"I\", \"s\", \"xxxxxxxx\", \"xxxx\"]\n",
    "\n",
    "#     # Remove Punctuation, and words containing numbers\n",
    "#     for ug in unigram_to_remove:\n",
    "#         unigram_pattern = f'(\\A{ug} )|( {ug} )|( {ug}\\Z)'\n",
    "#         sentence = re.sub(unigram_pattern, ' ', sentence)\n",
    "#     return sentence\n",
    "\n",
    "# df_complain_processed['complaint_remove_specific_unigram'] = df_complain_processed['complaint_lemmatise'].apply(clean_specific_unigram)\n",
    "# df_complain_processed\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unigram frequency\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "text = \" \".join(list(df['preprocessed_text']))\n",
    "uni_tokens = word_tokenize(text)\n",
    "unigram_df = pd.DataFrame({'unigram':uni_tokens})\n",
    "\n",
    "unigram_freq_df = unigram_df.groupby('unigram').size().reset_index(name='count').sort_values(by='count', ascending=False)\n",
    "unigram_freq_df.iloc[:49]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bigram\n",
    "import itertools\n",
    "from nltk import bigrams\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "\n",
    "text = list(df['preprocessed_text'])\n",
    "bigrams_2dlist = [list(bigrams(word_tokenize(txt))) for txt in text]\n",
    "bigrams_flattenlist = list(itertools.chain.from_iterable(bigrams_2dlist))\n",
    "\n",
    "bigram_df = pd.DataFrame({'bigram':bigrams_flattenlist})\n",
    "\n",
    "bigram_freq_df = bigram_df.groupby('bigram').size().reset_index(name='count').sort_values(by='count', ascending=False)\n",
    "bigram_freq_df.iloc[:49]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trigram\n",
    "import itertools\n",
    "from nltk import trigrams\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "\n",
    "text = list(df['preprocessed_text'])\n",
    "trigrams_2dlist = [list(trigrams(word_tokenize(txt))) for txt in text]\n",
    "trigrams_flattenlist = list(itertools.chain.from_iterable(trigrams_2dlist))\n",
    "\n",
    "trigram_df = pd.DataFrame({'trigram':trigrams_flattenlist})\n",
    "trigram_freq_df = trigram_df.groupby('trigram').size().reset_index(name='count').sort_values(by='count', ascending=False)\n",
    "trigram_freq_df.iloc[:49]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# word cloud of unigrams\n",
    "d = {}\n",
    "for a, x in unigram_freq_df.values:\n",
    "    d[a] = x\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "wordcloud = WordCloud()\n",
    "wordcloud.generate_from_frequencies(frequencies=d)\n",
    "plt.figure()\n",
    "plt.imshow(wordcloud, interpolation=\"bilinear\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Extraction\n",
    "\n",
    "- TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, TfidfTransformer\n",
    "\n",
    "tfidf = TfidfVectorizer(min_df=2, max_df=0.95, stop_words='english')\n",
    "dtm = tfidf.fit_transform(df['preprocessed_text'])\n",
    "dtm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ticket Category"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Topic Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Non-Negative Matrix Factorization (NMF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.decomposition import NMF\n",
    "# from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from gensim.models.coherencemodel import CoherenceModel\n",
    "from gensim.corpora.dictionary import Dictionary\n",
    "from gensim.models.nmf import Nmf\n",
    "from collections import Counter\n",
    "from operator import itemgetter\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = df['preprocessed_text'].str.split(' ')\n",
    "\n",
    "dictionary = Dictionary(texts)\n",
    "\n",
    "dictionary.filter_extremes(\n",
    "    no_below=3,\n",
    "    no_above=0.85,\n",
    "    keep_n=5000\n",
    ")\n",
    "\n",
    "corpus = [dictionary.doc2bow(text) for text in texts]\n",
    "\n",
    "topic_nums = list(np.arange(5, 40 + 1, 5))\n",
    "\n",
    "coherence_scores = []\n",
    "\n",
    "for num in topic_nums:\n",
    "    nmf = Nmf(\n",
    "        corpus=corpus,\n",
    "        num_topics=num,\n",
    "        id2word=dictionary,\n",
    "        chunksize=2000,\n",
    "        passes=5,\n",
    "        kappa=.1,\n",
    "        minimum_probability=0.01,\n",
    "        w_max_iter=300,\n",
    "        w_stop_condition=0.0001,\n",
    "        h_max_iter=100,\n",
    "        h_stop_condition=0.001,\n",
    "        eval_every=10,\n",
    "        normalize=True,\n",
    "        random_state=42\n",
    "    )\n",
    "    cm = CoherenceModel(\n",
    "        model=nmf,\n",
    "        texts=texts,\n",
    "        dictionary=dictionary,\n",
    "        coherence='c_v'\n",
    "    )\n",
    "    \n",
    "    coherence_scores.append(round(cm.get_coherence(), 5))\n",
    "    print(f'topic modelling done for iteration {num}')\n",
    "\n",
    "scores = list(zip(topic_nums, coherence_scores))\n",
    "best_num_topics = sorted(scores, key=itemgetter(1), reverse=True)[0][0]\n",
    "\n",
    "fig = plt.figure(figsize=(15, 7))\n",
    "\n",
    "plt.plot(\n",
    "    topic_nums,\n",
    "    coherence_scores,\n",
    "    linewidth=3,\n",
    "    color='#4287f5'\n",
    ")\n",
    "\n",
    "plt.xlabel(\"Topic Num\", fontsize=14)\n",
    "plt.ylabel(\"Coherence Score\", fontsize=14)\n",
    "plt.title('Coherence Score by Topic Number - Best Number of Topics: {}'.format(best_num_topics), fontsize=18)\n",
    "plt.xticks(np.arange(5, max(topic_nums) + 1, 5), fontsize=12)\n",
    "plt.yticks(fontsize=12)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Latent Dirichlet Allocation (LDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.coherencemodel import CoherenceModel\n",
    "from gensim.corpora.dictionary import Dictionary\n",
    "from gensim.models.ldamodel import LdaModel\n",
    "from collections import Counter\n",
    "from operator import itemgetter\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = df['preprocessed_text'].str.split(' ')\n",
    "\n",
    "dictionary = Dictionary(texts)\n",
    "\n",
    "dictionary.filter_extremes(\n",
    "    no_below=3,\n",
    "    no_above=0.85,\n",
    "    keep_n=5000\n",
    ")\n",
    "\n",
    "corpus = [dictionary.doc2bow(text) for text in texts]\n",
    "\n",
    "topic_nums = list(np.arange(5, 40 + 1, 5))\n",
    "\n",
    "coherence_scores = []\n",
    "\n",
    "for num in topic_nums:\n",
    "    lda = LdaModel(\n",
    "        corpus=corpus,\n",
    "        num_topics=num,\n",
    "        id2word=dictionary,\n",
    "        chunksize=2000,\n",
    "        passes=5,\n",
    "        minimum_probability=0.01,\n",
    "        alpha='symmetric',\n",
    "        per_word_topics=True,\n",
    "        eta=0.6,\n",
    "        eval_every=10,\n",
    "        random_state=42\n",
    "    )\n",
    "    cm = CoherenceModel(\n",
    "        model=lda,\n",
    "        texts=texts,\n",
    "        dictionary=dictionary,\n",
    "        coherence='c_v'\n",
    "    )\n",
    "    \n",
    "    coherence_scores.append(round(cm.get_coherence(), 5))\n",
    "    print(f'topic modelling done for iteration {num}')\n",
    "\n",
    "scores = list(zip(topic_nums, coherence_scores))\n",
    "best_num_topics = sorted(scores, key=itemgetter(1), reverse=True)[0][0]\n",
    "\n",
    "fig = plt.figure(figsize=(15, 7))\n",
    "\n",
    "plt.plot(\n",
    "    topic_nums,\n",
    "    coherence_scores,\n",
    "    linewidth=3,\n",
    "    color='#4287f5'\n",
    ")\n",
    "\n",
    "plt.xlabel(\"Topic Num\", fontsize=14)\n",
    "plt.ylabel(\"Coherence Score\", fontsize=14)\n",
    "plt.title('Coherence Score by Topic Number - Best Number of Topics: {}'.format(best_num_topics), fontsize=18)\n",
    "plt.xticks(np.arange(5, max(topic_nums) + 1, 5), fontsize=12)\n",
    "plt.yticks(fontsize=12)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Top2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from top2vec import Top2Vec\n",
    "\n",
    "umap_args = {'n_neighbors': 10,\n",
    "             'n_components': 5,\n",
    "             'metric': 'cosine',\n",
    "             \"random_state\": 42}\n",
    "hdbscan_args = {'min_cluster_size': 10,\n",
    "                'min_samples':5,\n",
    "                'metric': 'euclidean',\n",
    "                'cluster_selection_method': 'eom'}\n",
    "\n",
    "top2vec = Top2Vec(\n",
    "    documents= df.complaint_what_happened, \n",
    "    speed='deep-learn', \n",
    "    workers=8, \n",
    "    min_count = 0, \n",
    "    embedding_model='distiluse-base-multilingual-cased', \n",
    "    umap_args = umap_args, \n",
    "    hdbscan_args = hdbscan_args)\n",
    "\n",
    "top2vec.get_num_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BERTopic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate ticket category\n",
    "# LDA\n",
    "# NMF\n",
    "# Top2Vec\n",
    "# BERTopic\n",
    "\n",
    "# evaluate which is the best\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ticket Priority"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate ticket priority\n",
    "# based on overall sentiment score, polarity, and topic frequency\n",
    "# then abc ranking (20-30-50)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model building\n",
    "- data partition\n",
    "- machine learning models\n",
    "    - SVM\n",
    "    - KNN\n",
    "    - LogR\n",
    "    - NB\n",
    "    - Dtree\n",
    "    - random forest\n",
    "- evaluations\n",
    "    - accuracy, precision, recall, f1-score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
